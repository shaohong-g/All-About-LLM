{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6dfc5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import get_response_synthesizer\n",
    "import logging\n",
    "import sys, os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b654c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of text-ada-embedding-002\n",
    "d = 1536\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# vector_store = FaissVectorStore(faiss_index=faiss_index).from_persist_dir(\"./storage\")\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de19214",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=os.getenv(\"AZURE_EMBEDDING_MODEL\"),\n",
    "    deployment_name=os.getenv(\"AZURE_EMBEDDING_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_EMBEDDING_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_EMBEDDING_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_EMBEDDING_VERSION\"),\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e83cf",
   "metadata": {},
   "source": [
    "# llamaIndex\n",
    "- Example: Load resume and read from it\n",
    "- Document load -> Vector Store -> Query\n",
    "- https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a3681",
   "metadata": {},
   "source": [
    "## Document Load\n",
    "- https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e246fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='897d932f-3b5a-4a1b-9d8f-e157043f84bf', embedding=None, metadata={'page_label': '1', 'file_name': 'my_resume.pdf', 'file_path': 'data/my_resume.pdf', 'file_type': 'application/pdf', 'file_size': 250772, 'creation_date': '2025-04-27', 'last_modified_date': '2025-04-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"GAN SHAO HONG \\n(+65) 90855781 | shaohong.g97@gmail.com | www.linkedin.com/in/g-shaohong/ | https://github.com/shaohong-g  \\n \\nPROFESSIONAL SUMMARY \\n• Machine Learning Engineer with 3+ years of experience in developing highly scalable AI models, implementing ML \\npipelines, and deploying models in cloud environments.  \\n• Proficient in Python, TensorFlow, and PyTorch, with experience in distributed computing (GPU, AWS SageMaker) and \\ndata-driven decision-making.  \\n• Passionate about delivering cutting-edge AI solutions that enhance business operations and user experience.  \\n \\nEDUCATION \\nSingapore Management University  \\nBSc Information Systems (Business Analytics & Artificial Intelligence) Aug 2019 – Apr 2023 \\nCum Laude (Distinction) \\nRelated Modules: Deep Learning, Web Development, Social Analytics, Natural Language Communication \\n \\nNgee Ann Polytechnic  \\nDiploma in Business Studies (International Business) Apr 2014 – Mar 2017 \\nRelated Modules: Financial Management, Decision Support with Spreadsheets, Business Analytics \\n \\nEXPERIENCE \\nUBS \\nAI Research Scientist Jan 2025 – Present \\n• Apply Explainable AI (XAI) methods such as SHAP (SHapley Additive exPlanations) to improve interpretability and \\ntransparency in the legal litigation domain. \\n \\nSoftware Engineer (full-stack) Aug 2023 – Jan 2025 \\n• Core developer for Performance Data Mart, a one-stop application that aggregates data from multiple source systems, \\nwhich increases visibility in the data warehouse and reduces data gaps among stakeholders. \\n• Upgrade and update legacy codes used in Java Spring applications, oracle packages , and deployment pipelines in Azure \\nand Gitlab. \\n• Enhanced user experience and redesigned application visuals by decoupling and creating reusable UI components. \\n• Integrate AI chatbot to allow stakeholders to retrieve in-house information easily.  \\n• Developed Power BI dashboards extensively used by L2 and upper management stakeholders for compliance, \\nsuccessfully reducing SLA lead time by 10% to improve financial controller productivity.  \\n \\nAsurion  \\nIntern – Technology (Data Science, AI & Machine Learning) Jan 2023 – May 2023 \\n• Planned and implemented the Object Detection/Segmentation workflow lifecycle, including labeling, training, and model \\ndeployment in AWS SageMaker. \\n• Upgrade and update maintenance codes from yolov5 model to yolov8 model and integrate non-max suppression (NMS) \\nlogic/layer in the model architecture through onnx model framework. \\n• Retrain and fine-tune the existing model by adding two additional classes for phone screen detection using Tensorflow.  \\n• Create a web prototype to demonstrate live object detection inference from a webcam using TensorFlow.js. \\n \\nInfineon Technologies  \\nMachine Learning and Test Verification Intern Aug 2022 – Jan 2023 \\n• Explore state-of-the-art object detection architectures such as Faster RCNN, YOLO, and Single Shot Detector for object \\ndetection on sensor data. \\n• Created a customized labeling GUI to annotate radar frames against corresponding video frames, allowing reviewing of \\nbounding boxes in each data sample and automatically identifying bounding box's coordinates.  \\n• Benchmarked and significantly improved fps and mAP metrics for deploying models on Raspberry Pi devices. \\n \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='abb5dcdd-6203-42a7-99fe-16177741713b', embedding=None, metadata={'page_label': '2', 'file_name': 'my_resume.pdf', 'file_path': 'data/my_resume.pdf', 'file_type': 'application/pdf', 'file_size': 250772, 'creation_date': '2025-04-27', 'last_modified_date': '2025-04-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Neuron Mobility  \\nData Engineering Intern May 2022 – Aug 2022 \\n• Pipeline migration from existing Jobber 'jobs' in EC2 to Argo workflows.  \\n• Optimize codes using various implementations such as server-side cursors, object-oriented design patterns, and parallel \\nprocessing with Python Celery to reduce time and space complexity. \\n• Work with time series and geospatial data and expose to AWS services such as Redshift, RDS, S3, EC2, EKS, and ECR. \\n• Develop a Flask application that integrates with the Slack application and allows business users to retrieve their queries \\nfrom Redshift/RDS based on their inputs, thereby reducing the number of tickets, and automating the retrieval process. \\n \\nHewlett-Packard (HP)  \\nIntelligent Robotic Process Automation and Analytics Developer Jul 2021 – Jan 2022 \\n• Spearheaded end-to-end project life cycle of activities including analysis, design, testing , and deployment phases of \\nautomation workflows. \\n• Automated dashboard reporting workflow and reduced time spent from 8 hours to 20 minutes using Microsoft Power \\nAutomate, and Office Scripts (vba). \\n• Member of Intelligent Automation Circle and involved in Data Analytics team sharing . \\n \\nNOTABLE PROJECTS & HACKATHONS \\nUBS TechNOVA Hackathon – 2nd place Nov 2024 – Nov 2024 \\n• Developed an anomaly detection solution that analyzes conversations to identify potential compliance risks and flag \\ninstances of policy, regulatory, or legal violations. In talks on moving this to production. \\n• Tech stacks: LLMs and RAG technologies (Azure OpenAI, Azure Search), python Flask, and React web framework.  \\n \\nUBS AI Kettle Oct 2024 – Nov 2024 \\n• Kaggle-style competition on FX Trading prediction. (predicting transaction volumes of selected currency pairs)  \\n• Developed an LSTM model that outperformed the baseline score using PyTorch. \\n \\nCustom Faster-CNN Implementation  Nov 2022 – Dec 2022 \\n• Re-created fcnn architecture using TensorFlow and trained a car detection model with CUDA. \\n \\nSMU Ellipsis Tech Series 2022 sponsored by Goldman Sachs – Top 10 teams Aug 2022 – Aug 2022 \\n• Developed an integrated platform to encourage Fintech companies to invest in startups that align with their interest. \\n• Recommendation score is weighted based on key components such as collaborative filtering on similar users. \\n• Tech stacks: frontend (Vue, tailwind), backend (python Flask, SQLAlchemy, TensorFlow, sklearn), Kubernetes, AWS  \\n \\nCoursework: Social Analytics Jan 2022 – Apr 2022 \\n• Partnered with The Singapore Children's Society (SCS) to tackle the lack of engagement and social media presence using \\ntext and network analysis.  \\n• Tech stacks: Python (pandas, selenium, sklearn, nltk, genism, networkx), AWS Rekognition, AWS Comprehend  \\n \\nSKILLS & INTERESTS \\n• Programming Languages: Python, Java, MySQL, PHP, JavaScript \\n• Familiar Libraries / Frameworks: Python (Flask, Fastapi, NumPy, Pandas, Scikit-learn, Matplotlib, TensorFlow, PyTorch), \\nJavaScript (VueJs, React), Java (Spring) \\n• Trained in OS: Windows, Linux \\n• Work Programmes: Azure, AWS, Figma, Tableau, PowerBI, Gitlab, Argo \\n• Certificates:  \\no Microsoft Certified: Azure AI Fundamentals \\no Microsoft Certified: Azure Administrator Associate \\no AWS Certified Solutions Architect – Associate \\no Deep Learning Specialization from DeepLearning.AI \\no Oracle Certified Foundations Associate (Java) \\no SAS Certified Specialist: Machine Learning Using SAS Viya 3.5 \\no CodeIT Advanced: Advanced Data Structures & Algorithms \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader(input_files=[\"./data/my_resume.pdf\"])\n",
    "documents = reader.load_data()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc85d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '897d932f-3b5a-4a1b-9d8f-e157043f84bf',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '1',\n",
       "  'file_name': 'my_resume.pdf',\n",
       "  'file_path': 'data/my_resume.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 250772,\n",
       "  'creation_date': '2025-04-27',\n",
       "  'last_modified_date': '2025-04-27'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text=\"GAN SHAO HONG \\n(+65) 90855781 | shaohong.g97@gmail.com | www.linkedin.com/in/g-shaohong/ | https://github.com/shaohong-g  \\n \\nPROFESSIONAL SUMMARY \\n• Machine Learning Engineer with 3+ years of experience in developing highly scalable AI models, implementing ML \\npipelines, and deploying models in cloud environments.  \\n• Proficient in Python, TensorFlow, and PyTorch, with experience in distributed computing (GPU, AWS SageMaker) and \\ndata-driven decision-making.  \\n• Passionate about delivering cutting-edge AI solutions that enhance business operations and user experience.  \\n \\nEDUCATION \\nSingapore Management University  \\nBSc Information Systems (Business Analytics & Artificial Intelligence) Aug 2019 – Apr 2023 \\nCum Laude (Distinction) \\nRelated Modules: Deep Learning, Web Development, Social Analytics, Natural Language Communication \\n \\nNgee Ann Polytechnic  \\nDiploma in Business Studies (International Business) Apr 2014 – Mar 2017 \\nRelated Modules: Financial Management, Decision Support with Spreadsheets, Business Analytics \\n \\nEXPERIENCE \\nUBS \\nAI Research Scientist Jan 2025 – Present \\n• Apply Explainable AI (XAI) methods such as SHAP (SHapley Additive exPlanations) to improve interpretability and \\ntransparency in the legal litigation domain. \\n \\nSoftware Engineer (full-stack) Aug 2023 – Jan 2025 \\n• Core developer for Performance Data Mart, a one-stop application that aggregates data from multiple source systems, \\nwhich increases visibility in the data warehouse and reduces data gaps among stakeholders. \\n• Upgrade and update legacy codes used in Java Spring applications, oracle packages , and deployment pipelines in Azure \\nand Gitlab. \\n• Enhanced user experience and redesigned application visuals by decoupling and creating reusable UI components. \\n• Integrate AI chatbot to allow stakeholders to retrieve in-house information easily.  \\n• Developed Power BI dashboards extensively used by L2 and upper management stakeholders for compliance, \\nsuccessfully reducing SLA lead time by 10% to improve financial controller productivity.  \\n \\nAsurion  \\nIntern – Technology (Data Science, AI & Machine Learning) Jan 2023 – May 2023 \\n• Planned and implemented the Object Detection/Segmentation workflow lifecycle, including labeling, training, and model \\ndeployment in AWS SageMaker. \\n• Upgrade and update maintenance codes from yolov5 model to yolov8 model and integrate non-max suppression (NMS) \\nlogic/layer in the model architecture through onnx model framework. \\n• Retrain and fine-tune the existing model by adding two additional classes for phone screen detection using Tensorflow.  \\n• Create a web prototype to demonstrate live object detection inference from a webcam using TensorFlow.js. \\n \\nInfineon Technologies  \\nMachine Learning and Test Verification Intern Aug 2022 – Jan 2023 \\n• Explore state-of-the-art object detection architectures such as Faster RCNN, YOLO, and Single Shot Detector for object \\ndetection on sensor data. \\n• Created a customized labeling GUI to annotate radar frames against corresponding video frames, allowing reviewing of \\nbounding boxes in each data sample and automatically identifying bounding box's coordinates.  \\n• Benchmarked and significantly improved fps and mAP metrics for deploying models on Raspberry Pi devices. \\n \", path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3dd25",
   "metadata": {},
   "source": [
    "## Insert parsed documents to vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4842798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18f53cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d476075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://black-exposure.openai.azure.com/openai/deployments/black-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"How many jobs have the applicants done? Give the company name, role as well as time.\"\n",
    "query = \"How many jobs have the applicants done from 2022-2023?\"\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\") # refine , context_only, accumulate, compact (default)\n",
    "query_engine = index.as_query_engine(response_synthesizer=response_synthesizer)\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d74a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: a6455d01-5069-484e-ab17-94bf8c26202e): Neuron Mobility  \n",
      "Data Engineering Intern May 2022 – Aug 2022 \n",
      "• Pipeline migration from existing...\n",
      "\n",
      "> Source (Doc id: 153458dc-dc80-4b58-b479-11b22aea1ee8): GAN SHAO HONG \n",
      "(+65) 90855781 | shaohong.g97@gmail.com | www.linkedin.com/in/g-shaohong/ | https:...\n",
      "query was: How many jobs have the applicants done from 2022-2023?\n",
      "answer was: The applicant has done four jobs from 2022 to 2023:\n",
      "\n",
      "1. **Neuron Mobility** (Data Engineering Intern) - May 2022 to August 2022  \n",
      "2. **Infineon Technologies** (Machine Learning and Test Verification Intern) - August 2022 to January 2023  \n",
      "3. **Asurion** (Intern – Technology, Data Science, AI & Machine Learning) - January 2023 to May 2023  \n",
      "4. **UBS** (Software Engineer, full-stack) - August 2023 to January 2025 (part of this role falls in 2023).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response.get_formatted_sources())\n",
    "print(\"query was:\", query)\n",
    "print(\"answer was:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['node', 'score', 'class_name'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "nodes = [json.loads(x.to_json()) for x in response.source_nodes]\n",
    "node1 = nodes[0]\n",
    "node1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20ef45b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48575446009635925 0.4998507499694824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id_': 'a6455d01-5069-484e-ab17-94bf8c26202e',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '2',\n",
       "  'file_name': 'my_resume.pdf',\n",
       "  'file_path': 'data/my_resume.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 250772,\n",
       "  'creation_date': '2025-04-27',\n",
       "  'last_modified_date': '2025-04-27'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {'1': {'node_id': 'abb5dcdd-6203-42a7-99fe-16177741713b',\n",
       "   'node_type': '4',\n",
       "   'metadata': {'page_label': '2',\n",
       "    'file_name': 'my_resume.pdf',\n",
       "    'file_path': 'data/my_resume.pdf',\n",
       "    'file_type': 'application/pdf',\n",
       "    'file_size': 250772,\n",
       "    'creation_date': '2025-04-27',\n",
       "    'last_modified_date': '2025-04-27'},\n",
       "   'hash': '05b49a6b9291d425546cdaa3a50e53191769ff57a18d8517f3f8ce58934dc150',\n",
       "   'class_name': 'RelatedNodeInfo'}},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text': \"Neuron Mobility  \\nData Engineering Intern May 2022 – Aug 2022 \\n• Pipeline migration from existing Jobber 'jobs' in EC2 to Argo workflows.  \\n• Optimize codes using various implementations such as server-side cursors, object-oriented design patterns, and parallel \\nprocessing with Python Celery to reduce time and space complexity. \\n• Work with time series and geospatial data and expose to AWS services such as Redshift, RDS, S3, EC2, EKS, and ECR. \\n• Develop a Flask application that integrates with the Slack application and allows business users to retrieve their queries \\nfrom Redshift/RDS based on their inputs, thereby reducing the number of tickets, and automating the retrieval process. \\n \\nHewlett-Packard (HP)  \\nIntelligent Robotic Process Automation and Analytics Developer Jul 2021 – Jan 2022 \\n• Spearheaded end-to-end project life cycle of activities including analysis, design, testing , and deployment phases of \\nautomation workflows. \\n• Automated dashboard reporting workflow and reduced time spent from 8 hours to 20 minutes using Microsoft Power \\nAutomate, and Office Scripts (vba). \\n• Member of Intelligent Automation Circle and involved in Data Analytics team sharing . \\n \\nNOTABLE PROJECTS & HACKATHONS \\nUBS TechNOVA Hackathon – 2nd place Nov 2024 – Nov 2024 \\n• Developed an anomaly detection solution that analyzes conversations to identify potential compliance risks and flag \\ninstances of policy, regulatory, or legal violations. In talks on moving this to production. \\n• Tech stacks: LLMs and RAG technologies (Azure OpenAI, Azure Search), python Flask, and React web framework.  \\n \\nUBS AI Kettle Oct 2024 – Nov 2024 \\n• Kaggle-style competition on FX Trading prediction. (predicting transaction volumes of selected currency pairs)  \\n• Developed an LSTM model that outperformed the baseline score using PyTorch. \\n \\nCustom Faster-CNN Implementation  Nov 2022 – Dec 2022 \\n• Re-created fcnn architecture using TensorFlow and trained a car detection model with CUDA. \\n \\nSMU Ellipsis Tech Series 2022 sponsored by Goldman Sachs – Top 10 teams Aug 2022 – Aug 2022 \\n• Developed an integrated platform to encourage Fintech companies to invest in startups that align with their interest. \\n• Recommendation score is weighted based on key components such as collaborative filtering on similar users. \\n• Tech stacks: frontend (Vue, tailwind), backend (python Flask, SQLAlchemy, TensorFlow, sklearn), Kubernetes, AWS  \\n \\nCoursework: Social Analytics Jan 2022 – Apr 2022 \\n• Partnered with The Singapore Children's Society (SCS) to tackle the lack of engagement and social media presence using \\ntext and network analysis.  \\n• Tech stacks: Python (pandas, selenium, sklearn, nltk, genism, networkx), AWS Rekognition, AWS Comprehend  \\n \\nSKILLS & INTERESTS \\n• Programming Languages: Python, Java, MySQL, PHP, JavaScript \\n• Familiar Libraries / Frameworks: Python (Flask, Fastapi, NumPy, Pandas, Scikit-learn, Matplotlib, TensorFlow, PyTorch), \\nJavaScript (VueJs, React), Java (Spring) \\n• Trained in OS: Windows, Linux \\n• Work Programmes: Azure, AWS, Figma, Tableau, PowerBI, Gitlab, Argo \\n• Certificates:  \\no Microsoft Certified: Azure AI Fundamentals \\no Microsoft Certified: Azure Administrator Associate \\no AWS Certified Solutions Architect – Associate \\no Deep Learning Specialization from DeepLearning.AI \\no Oracle Certified Foundations Associate (Java) \\no SAS Certified Specialist: Machine Learning Using SAS Viya 3.5 \\no CodeIT Advanced: Advanced Data Structures & Algorithms\",\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': 0,\n",
       " 'end_char_idx': 3482,\n",
       " 'metadata_seperator': '\\n',\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'class_name': 'TextNode'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(node1[\"score\"], nodes[1][\"score\"])\n",
    "node1[\"node\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83725c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
